---
title: "Chapter 3 Assessment"
author: 'Seth Harrison'
date: '`r format(Sys.time(), "%b %d, %Y")`'
output: 
  bookdown::pdf_document2:
    toc: false
---

**Directions:** Strike-through false statements using `~~strikethrough~~`.  Bold all true statements and answers.  By entering your name on the document you turn in, you are acknowledging that the work in the document is entirely your own unless specified otherwise in the document.  Compile your document using `Knit PDF` and turn in a stapled hardcopy (Walker 237) no later than 5 PM, October 11, 2019.  Use inline `R` expressions rather than hardcoding your numeric answers.  Make sure you commit all changes to your repository prior to the due date.


```{r, label = "SETUP", echo = FALSE, results= 'hide', message = FALSE, warning = FALSE}
set.seed(123)
library(knitr)
library(ISLR)
knitr::opts_chunk$set(comment = NA, fig.align = 'center', fig.height = 5, fig.width = 5,  warning = FALSE, message = FALSE, tidy.opts=list(blank = TRUE, width.cutoff = 75))
```


1. Why is linear regression important to understand? Select all that apply:

* ~~The linear model is often correct.~~

* **Linear regression is very extensible and can be used to capture nonlinear effects.**

* **Simple methods can outperform more complex ones if the data are noisy.**

* **Understanding simpler methods sheds light on more complex ones.**




2. You may want to reread the paragraph on confidence intervals on page 66 of the textbook before trying this question (the distinctions are subtle).  Which of the following are true statements? Select all that apply:

* ~~A 95% confidence interval formula is a random interval that is expected to contain the true parameter 95% of the time.~~

* ~~The true parameter is a random value that has 95% chance of falling in the 95% confidence interval.~~

* **I perform a linear regression and get a 95% confidence interval from 0.4 to 0.5. There is a 95% probability that the true parameter is between 0.4 and 0.5.**

* **The true parameter (unknown to me) is 0.5. If I repeatedly sample data and construct 95% confidence intervals, the intervals will contain 0.5 approximately 95% of the time.**



$\pagebreak$

3.  We run a linear regression and the slope estimate is 0.5 with estimated standard error of 0.2. What is the largest value of $b$ for which we would NOT reject the null hypothesis that $\beta_1=b$? 

a.  Assume a normal approximation to the $t$ distribution, and that we are using the 5% significance level for a two-sided test; use two significant digits of accuracy.

```{r}
1.96 * .02
```

**0.0392**


b.  Use a $t$ distribution with 10 degrees of freedom, and assume that we are using the 5% significance level for a two-sided test; use two significant digits of accuracy.


```{r}
(1.96 * .02) / sqrt(11)
```

**0.0118**




4. Which of the following indicates a fairly strong relationship between $X$ and $Y$?

* **$R^2 = 0.9$**

* The p-value for the null hypothesis $\beta_1 = 0$ is 0.0001.

* The t-statistic for the null hypothesis $\beta_1 = 0$ is 30.


$\pagebreak$

5. Given the following: 

```{r}
str(Credit)
ModEthnic <- lm(Balance ~ Ethnicity, data = Credit)
summary(ModEthnic)
```



$\pagebreak$

a. According to the balance vs ethnicity model (`ModEthnic`), what is the predicted balance for an Asian in the data set? (within 0.01 accuracy)

**`r 531 - 18.69`**


b. What is the predicted balance for an African American? (within .01 accuracy)

**531**


c. Construct a 90% confidence interval for the average credit card balance for Asians.

```{r}
library(dplyr)
creditAsian <- Credit %>% filter(Ethnicity == "Asian")
ModAsian <- lm(Balance ~ 1, creditAsian)
confint(ModAsian, level = .90)
```

**Between 433.1844 and 591.443**

d. Construct a 92% prediction interval for Joe's (who is African American) credit card balance.

```{r}
creditAfricanAmerican <- Credit %>% filter(Ethnicity == "African American")
ModAfricanAmerican <- lm(Balance ~ 1, creditAfricanAmerican)
confint(ModAfricanAmerican, level = .92)
```


**Between 444.6573 and 617.3427**





$\pagebreak$

6. Given the following:

```{r}
mod <- lm(Rating ~ poly(Limit, 2, raw = TRUE) + poly(Cards, 2, raw = TRUE) + 
            Married + Student + Education, data = Credit)
summary(mod)
```


  a. Use `mod` to predict the `Rating` for an individual that has a credit card limit of $6,000, has 4 credit cards, is married, and is not a student, and has an undergraduate degree (`Education` = 16).
  
```{r}
25.79 + (.06529 * 6000) + (1.320 * 10^(-7) * 6000) + (7.615 * 4) + (-.3972 * 4) + (2.295 * 1) + (-.2774 * 16)
```

**444.2586**
  
  b. Use `mod` to predict the `Rating` for an individual that has a credit card limit of
$12,000, has 2 credit cards, is married, is not a student, and has an eighth grade education (`Education` = 8).

```{r}
25.79 + (.06529 * 12000) + (1.320 * 10^(-7) * 12000) + (7.615 * 2) + (-.3972 * 2) + (2.295 * 1) + (-.2774 * 8)
```

**823.783**

  c . Construct and interpret a 90% confidence interval for $\beta_5$ (a married person).

```{r}
CreditMarried <- Credit %>% filter(Married == "Yes")
modRatingMarried <- lm(Rating ~ 1, CreditMarried)
confint(modRatingMarried, level = .9)
```

**We would expect our confidence interval of 342.8019 to 376.1124 to contain the credit rating of the population 90% of the time**


$\pagebreak$

7. Given the following:

```{r}
site <- "http://faculty.marshall.usc.edu/gareth-james/ISL/Advertising.csv"
Advertising <- read.csv(file = site)
str(Advertising)
modSales <- lm(sales ~ TV + radio + TV:radio, data = Advertising)
summary(modSales)
coef(modSales)
```


a. According to the model for sales vs TV interacted with radio (`modSales`), what is the effect of an additional 1 unit of radio advertising if TV = 25? (with 4 decimal accuracy)

**An increase in radio by one if TV = 25 will result in an increase of `r (1 * .02886) + (25 * .001086)`**


b.  What if TV = 300? (with 4 decimal accuracy)

**An increase in radio by one if TV = 300 will result in an increase of `r (1 * .02886) + (300 * .001086)`**


8.  What is the difference between `lm(y ~ x*z)` and `lm(y ~ I(x*z))`, when `x` and `z` are both numeric variables?

*  ~~The first one includes an interaction term between `x` and `z`, whereas the second uses the product of `x` and `z` as a predictor in the model.~~

* ~~The second one includes an interaction term between `x` and `z`, whereas the first uses the product of `x` and `z` as a predictor in the model.~~

* ~~The first includes only an interaction term for `x` and `z`, while the second includes both interaction effects and main effects.~~

* **The second includes only an interaction term for `x` and `z`, while the first includes both interaction effects and main effects.**


$\pagebreak$

9. Given the following model:

```{r, fig.height = 3, fig.width = 5}
modBalance <- lm(balance ~ student + income + student:income, data = Default)
library(ggplot2)
ggplot(data = Default, aes(x = income, y = balance, color = student)) + 
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE) +
  theme_bw()
```

Which of the following statements are true?

* **In the `modBalance` model, the estimate of $\beta_3$ is negative.** 

*  ~~One advantage of using linear models is that the true regression function is often linear.~~ 

*  ~~If the F statistic is significant, all of the predictors have statistically significant effects.~~ 

*  **In a linear regression with several variables, a variable has a positive regression coefficient if and only if its correlation with the response is positive.**


